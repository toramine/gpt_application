import { LLMChain } from "langchain.chains";
import { ChatOpenAI } from "langchain.chat_models";
import { PromptTemplate } from "langchain.prompts";

require("dotenv").config();

const router = require("express").Router();


//postでモデルの種類とプロンプトを受け取ってgptapiを実行しsendする
router.post("/performance", async (req, res) => {

  const model = req.body.model; //3.5turbo or 4
  const templateFlag = req.body.templateFlag; //テンプレートを使ってるか

  if (templateFlag) {
    const template = req.body.template; //保存したテンプレート
    const inputVariables = req.body.inputVariables; //使用する変数の配列
    const inputObjects= req.body.inputObjects; //変数と変数の中身
  } else {
    const contents= req.body.contents; //変数と変数の中身
  }

  //テンプレートを使う場合と使わない場合を分ける必要がある？分けた方が楽かも
  //使わない場合はmodel, contentsでいける
  //使う場合はinputVariables,contentsとtemplateが必要
  //使う場合はcallの時に設定するオブジェクトを作る必要がある

  try {

    // LLMの準備
    const llm = new ChatOpenAI({ model_name: model, temperature: 0.5 });

    //プロンプトテンプレートの設定
    const prompt = new PromptTemplate({
      inputVariables: inputVariables,
      template: template,
    });

    // チェーンの準備
    const chain = new LLMChain({ llm: llm, prompt });

    let res = await chain.call({ question: "なんとかかんとか" });

    console.log(response["text"]);
    res.send({ response["text"] });
  } catch (error) {
    console.error(error);
    res.send(error);
  }
});

module.exports = router;
